{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as plt_colors\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')\n",
    "import scipy.stats as st\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "from holoviews import dim\n",
    "from IPython.display import Markdown, display\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rc('xtick', labelsize=14)     \n",
    "matplotlib.rc('ytick', labelsize=14)\n",
    "matplotlib.rc('axes', labelsize=14, titlesize=14)\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import hvplot.pandas\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "\n",
    "from counts_analysis.c_utils import COUNTS_CSV, CLASSES, set_settings, set_counts_v2, rename_columns\n",
    "\n",
    "#== Load Datasets ==#\n",
    "df = pd.read_csv(COUNTS_CSV['counts'])\n",
    "df = rename_columns(df)\n",
    "# Dataset without problematic classes (Gyrodinium, Pseudo-nitzchia chain)\n",
    "df_ = df[df['class'].isin(CLASSES)].reset_index(drop=True)\n",
    "data = df.copy()\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "#=== Set count forms & settings ===#\n",
    "# COUNT\n",
    "volumetric_counts = set_counts_v2('cells/mL', micro_default=True)\n",
    "\n",
    "raw_counts = set_counts_v2('count', micro_default=False)\n",
    "raw_counts_pred = set_counts_v2('count', micro_default=False, automated=True)\n",
    "\n",
    "vol_time_counts = set_counts_v2('count', micro_default=True)\n",
    "\n",
    "class_percentage_counts = set_counts_v2('class percentage', micro_default=False) \n",
    "\n",
    "rel_counts = set_counts_v2('relative abundance', micro_default=False)\n",
    "rel_counts = ['Lab-micro count relative abundance'] + list(rel_counts[1:])\n",
    "\n",
    "class_percentage_counts_pred = set_counts_v2('class percentage', micro_default=False, automated=True)\n",
    "class_percentage_counts_pred = ['Lab-micro class percentage'] + list(class_percentage_counts_pred[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_side_by_side(dfs:list, captions:list):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    combined = dict(zip(captions, dfs))\n",
    "    for caption, df in combined.items():\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += \"\\xa0\\xa0\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from counts_analysis.plot_class_summary import plot_summary_both_count_forms, plot_class_summary\n",
    "\n",
    "def compute_volumetric(spc_camera, data):\n",
    "    \"\"\"\n",
    "    Usage\n",
    "    \n",
    "    >>> compute_volumetric(spc_camera='Auto-Pier', data)\n",
    "    >>> compute_volumetric(spc_camera='SPC-Pier', data)\n",
    "    \n",
    "    \"\"\"\n",
    "    if 'Pier' in spc_camera:\n",
    "        normalization_factor = 160\n",
    "    else:\n",
    "        normalization_factor = 60\n",
    "    data[f'{spc_camera} cells/mL'] = data[f'{spc_camera} count'] / normalization_factor\n",
    "    return data\n",
    "\n",
    "def compute_class_percentage(raw_count, data):\n",
    "    if 'cells/mL' in raw_count:\n",
    "        relative_column = 'Lab-micro cells/mL class percentage'\n",
    "    else:\n",
    "        relative_column = '{} class percentage'.format(raw_count.split(\" count\")[0])\n",
    "    data[relative_column] = data.groupby('datetime')[raw_count].apply(lambda x: x / x.sum() * 100.0 if sum(x) != 0 else x)\n",
    "    return data\n",
    "\n",
    "def compute_relative_abundance(raw_count, data):\n",
    "    if 'cells/mL' in raw_count:\n",
    "        relative_column = 'Lab-micro cells/mL relative abundance'\n",
    "    else:\n",
    "        relative_column = '{} relative abundance'.format(raw_count.split(\" count\")[0])\n",
    "    data[relative_column] = data.groupby('class')[raw_count].apply(lambda x: x / x.sum() * 100.0 if sum(x) != 0 else x)\n",
    "    return data\n",
    "\n",
    "def preprocess_raw_counts(count_form, raw_counts, data):\n",
    "    if count_form == 'volumetric':\n",
    "        compute_fn = compute_volumetric\n",
    "        \n",
    "    elif count_form == 'class percentage':\n",
    "        compute_fn = compute_class_percentage\n",
    "        \n",
    "    elif count_form == 'relative abundance':\n",
    "        compute_fn = compute_relative_abundance\n",
    "    \n",
    "    for rc in raw_counts:\n",
    "        data = compute_fn(rc, data)\n",
    "    return data\n",
    "\n",
    "#todo maybe load dataset???\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "data = preprocess_raw_counts('class percentage', raw_counts, data)\n",
    "data = preprocess_raw_counts('relative abundance', raw_counts, data)\n",
    "\n",
    "data = preprocess_raw_counts('class percentage', raw_counts_pred, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_summary(counts, data, relative=False):\n",
    "    \"\"\" Plot individual summaries of each class\n",
    "\n",
    "    Usage\n",
    "\n",
    "    >>> plot_class_summary(rc_counts, cls_df)\n",
    "\n",
    "    Args:\n",
    "        counts:\n",
    "        data:\n",
    "        relative:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    fontscale = 1.5\n",
    "    title_pre = 'Compared Counts' if not relative else '[Relative Abundance]'\n",
    "    xy = 'Count' if not relative else 'Relative Abundance'\n",
    "    max_val = max(data[list(counts)].max()) + 10\n",
    "\n",
    "    # boxwhisker plot\n",
    "    rot = 0 if not relative else 5\n",
    "    bx = data.groupby('datetime')[counts].sum().hvplot.hist(y=list(counts),\n",
    "                                                           group_label='Sampling Technique',\n",
    "                                                           value_label=xy,\n",
    "                                                           label='{} Distribution'.format(title_pre),\n",
    "                                                           rot=rot)\\\n",
    "        .opts(tools=['hover'], width=400, height=500, show_legend=False, fontscale=fontscale)\n",
    "\n",
    "    # time series\n",
    "    ts = data.groupby('datetime')[counts].sum().hvplot.line(rot=30, value_label='Total Count', group_label='Sampling Techniques', label=f'{title_pre} Time Series').\\\n",
    "        opts(height=500, width=800, legend_position='top_right', fontscale=fontscale)\n",
    "\n",
    "    # correlation plot\n",
    "    dot_size, alpha = 8, 0.6\n",
    "    line_width = 5\n",
    "\n",
    "    sc1 = hv.Scatter(data, counts[0], [counts[1], 'datetime', 'class'], label='lab - micro').opts(size=dot_size, alpha=alpha, tools=['hover'], fontscale=fontscale, color='blue')\n",
    "#     reg = hv.Slope.from_scatter(sc1).opts(alpha=alpha, tools=['hover'], fontscale=fontscale, color='blue', line_width=line_width)\n",
    "    reg, predict_ci, predict_mean_ci = get_linear_fit([counts[0], counts[1]], data, color='blue', fontscale=1.5, line_width=5)\n",
    "    corr1 = sc1 * reg * predict_ci * predict_mean_ci\n",
    "\n",
    "    sc2 = hv.Scatter(data, counts[0], [counts[2], 'datetime', 'class'], label='pier - micro').opts(size=dot_size, alpha=alpha, tools=['hover'], fontscale=fontscale, color='gold')\n",
    "#     reg2 = hv.Slope.from_scatter(sc2).opts(alpha=alpha, tools=['hover'], fontscale=fontscale, color='gold', line_width=line_width)\n",
    "    reg, predict_ci, predict_mean_ci = get_linear_fit([counts[0], counts[2]], data, color='gold', fontscale=1.5, line_width=5)\n",
    "    corr2 = sc2 * reg * predict_ci * predict_mean_ci \n",
    "\n",
    "    sc3 = hv.Scatter(data, counts[1], [counts[2], 'datetime', 'class'], label='pier - lab').opts(size=dot_size, alpha=alpha, tools=['hover'], fontscale=fontscale, color='red')\n",
    "#     reg3 = hv.Slope.from_scatter(sc3).opts(alpha=alpha, tools=['hover'], fontscale=fontscale, color='red', line_width=line_width)\n",
    "    reg, predict_ci, predict_mean_ci = get_linear_fit([counts[1], counts[2]], data, color='red', fontscale=1.5, line_width=5)\n",
    "    corr3 = sc3 * reg * predict_ci * predict_mean_ci \n",
    "\n",
    "#     corr = sc1*sc2*sc3*reg*reg2*reg3\n",
    "    corr = (corr1 * corr2 * corr3).opts(xlabel=xy , ylabel=xy,\n",
    "                                            title=f'{title_pre} Correlation', xlim=(0, max_val), ylim=(0, max_val), tools=['hover'], width=650, height=500, legend_position='right')\n",
    "\n",
    "    cls_plot = hv.Layout(bx + ts + corr).cols(3)\n",
    "\n",
    "    return cls_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_class_summary(cls, x, y, x_relative=False, y_relative=True, classifier=False):\n",
    "    def plot_class_summary_2method(counts, data, relative=False, color=None):\n",
    "        \"\"\" Plot individual summaries of each class\n",
    "\n",
    "        Usage\n",
    "\n",
    "        >>> plot_class_summary(rc_counts, cls_df)\n",
    "\n",
    "        Args:\n",
    "            counts:\n",
    "            data:\n",
    "            relative:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        fontscale = 1.5\n",
    "        title_pre = '[{}]'.format(cls) if not relative else '[Relative Abundance]'\n",
    "        xy = 'Count' if not relative else 'Relative Abundance'\n",
    "        max_val = max(data[list(counts)].max()) + 10\n",
    "\n",
    "        # boxwhisker plot\n",
    "        rot = 0 if not relative else 5\n",
    "        bx = data.groupby('datetime')[counts].sum().hvplot.hist(y=list(counts),\n",
    "                                                               label='{} Distribution'.format(title_pre),\n",
    "                                                                xlabel='Count Value', ylabel='Frequency of Count',\n",
    "                                                               rot=rot,\n",
    "                                                               color=color[:2])\\\n",
    "            .opts(tools=['hover'], width=400, height=500, fontscale=fontscale, show_legend=False)\n",
    "\n",
    "        # time series\n",
    "        ts = data.groupby('datetime')[counts].sum().hvplot.line(rot=30, value_label='Count', group_label='Sampling Techniques', label=f'{title_pre} Time Series', color=color[:2]).\\\n",
    "            opts(height=500, width=800, legend_position='top_right', fontscale=fontscale)\n",
    "\n",
    "        # correlation plot\n",
    "        dot_size, alpha = 8, 0.6\n",
    "        line_width = 5\n",
    "\n",
    "        sc1 = hv.Scatter(data, counts[0], [counts[1], 'datetime', 'class'], label='Raw Data').opts(size=dot_size, alpha=alpha, tools=['hover'], color=color[-1], fontscale=fontscale)\n",
    "#         reg = hv.Slope.from_scatter(sc1).opts(alpha=alpha, tools=['hover'], color=color[-1], fontscale=fontscale, line_width=line_width)\n",
    "        reg, predict_ci, predict_mean_ci = get_linear_fit(counts, data, color=color[-1], fontscale=1.5, line_width=5)\n",
    "#         corr = (sc1*reg * predict_ci * predict_mean_ci)\n",
    "\n",
    "        corr = (sc1*reg * predict_ci * predict_mean_ci).opts(xlabel=counts[0] , ylabel=counts[1],\n",
    "                                                title=f'{title_pre} Correlation', xlim=(0, max_val), ylim=(0, max_val), tools=['hover'], width=650, height=500, legend_position='right')\n",
    "\n",
    "        cls_plot = hv.Layout(bx + ts + corr).cols(3)\n",
    "\n",
    "        return cls_plot\n",
    "    \n",
    "    def filter_class(cls, x_data, y_data):\n",
    "        x_cls_df = x_data[x_data['class'] == cls].reset_index(drop=True)\n",
    "        y_cls_df = y_data[y_data['class'] == cls].reset_index(drop=True)\n",
    "        return x_cls_df, y_cls_df\n",
    "\n",
    "    def plot_summary(x, y):\n",
    "        x_count, x_data, x_relative = x\n",
    "        y_count, y_data, y_relative = y\n",
    "        datetime_col = ['datetime']\n",
    "        display_side_by_side([x_data[datetime_col + list(x_count)], y_data[datetime_col + list(y_count)]], ['raw', 'class percentage'])\n",
    "        printmd('### Sum total over N=26 days')\n",
    "        sum_counts = pd.DataFrame(x_data[list(x_count)].sum(), columns=['sum']).T\n",
    "        x_desc = pd.concat([x_data[list(x_count)].describe(), sum_counts])\n",
    "        sum_counts = pd.DataFrame(y_data[list(y_count)].sum(), columns=['sum']).T\n",
    "        y_desc = pd.concat([y_data[list(y_count)].describe(), sum_counts])\n",
    "\n",
    "        display_side_by_side([x_desc, y_desc], ['raw descriptors', 'relative descriptors'])\n",
    "        \n",
    "        \n",
    "        plot1 = plot_class_summary_2method([x_count[0], x_count[1]], x_data, relative=x_relative, color=['blue', 'orange', 'blue'])\n",
    "        plot2 = plot_class_summary_2method([x_count[0], x_count[2]], x_data, relative=x_relative, color=['blue', 'green', 'gold'])\n",
    "        plot3 = plot_class_summary_2method([x_count[1], x_count[2]], x_data, relative=x_relative, color=['orange', 'green', 'red'])\n",
    "        \n",
    "        plot4 = plot_class_summary(x_count, x_data, relative=x_relative)\n",
    "\n",
    "        return hv.Layout(plot4 + plot1 + plot2 + plot3 ).cols(3).opts(shared_axes=False)\n",
    "\n",
    "    x_df, y_df = filter_class(cls, x, y)\n",
    "    printmd(f'# {cls} | Classifier Counts ({classifier})')\n",
    "    if classifier:\n",
    "        x_counts, y_counts = raw_counts_pred, class_percentage_counts_pred\n",
    "    else:\n",
    "        x_counts, y_counts = raw_counts, class_percentage_counts\n",
    "    return plot_summary((x_counts, x_df, x_relative), (y_counts, y_df, y_relative))\n",
    "\n",
    "printmd('# Sample of Running `_plot_class_summary()`')\n",
    "x_relative = False\n",
    "y_relative = True\n",
    "cls = 'Akashiwo'\n",
    "\n",
    "DATASET = data\n",
    "CLASSIFIER = False\n",
    "# _plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_fit(counts, data, color, fontscale=1.5, line_width=5):\n",
    "    x = data[counts[0]].values\n",
    "    y = data[counts[1]].values\n",
    "    X = sm.add_constant(x)\n",
    "    res = sm.OLS(y, X).fit()\n",
    "    printmd(f'### {counts}')\n",
    "    print(res.summary())\n",
    "    \n",
    "    st, reg_data, ss2 = summary_table(res, alpha=0.05)\n",
    "    fittedvalues = reg_data[:, 2]\n",
    "    predict_mean_se  = reg_data[:, 3]\n",
    "    predict_mean_ci_low, predict_mean_ci_upp = reg_data[:, 4:6].T\n",
    "    predict_ci_low, predict_ci_upp = reg_data[:, 6:8].T\n",
    "    \n",
    "    X = X[:,1]\n",
    "    reg = hv.Curve(list(zip(X, fittedvalues)), label='Linear Fit').opts(tools=['hover'], color=color, fontscale=fontscale, line_width=line_width, alpha=0.8)\n",
    "    predict_ci = hv.Area((X, predict_ci_low, predict_ci_upp), vdims=['y', 'y2'], label='95% Confidence Band').opts(alpha=0.2, color=color)\n",
    "    predict_mean_ci = hv.Area((X, predict_mean_ci_low, predict_mean_ci_upp), vdims=['y', 'y2'], label='95% Prediction Band').opts(alpha=0.4, color=color)\n",
    "    \n",
    "    return reg, predict_ci, predict_mean_ci\n",
    "\n",
    "def plot_class_summary_2method(counts, data, relative=False, color=None):\n",
    "    \"\"\" Plot individual summaries of each class\n",
    "\n",
    "    Usage\n",
    "\n",
    "    >>> plot_class_summary(rc_counts, cls_df)\n",
    "\n",
    "    Args:\n",
    "        counts:\n",
    "        data:\n",
    "        relative:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    fontscale = 1.5\n",
    "    title_pre = '[{}]'.format(cls) if not relative else '[Relative Abundance]'\n",
    "    xy = 'Count' if not relative else 'Relative Abundance'\n",
    "    max_val = max(data[list(counts)].max()) + 10\n",
    "\n",
    "    # correlation plot\n",
    "    dot_size, alpha = 8, 0.6\n",
    "    line_width = 5\n",
    "\n",
    "    sc1 = hv.Scatter(data, counts[0], [counts[1], 'datetime', 'class'], label='Raw Data').opts(size=dot_size, tools=['hover'], color=color[-1], fontscale=fontscale)\n",
    "#     reg = hv.Slope.from_scatter(sc1, label='Linear Fit').opts(alpha=alpha, tools=['hover'], color=color[-1], fontscale=fontscale, line_width=line_width)\n",
    "    \n",
    "#     x = data[counts[0]].values\n",
    "#     y = data[counts[1]].values\n",
    "#     X = sm.add_constant(x)\n",
    "#     res = sm.OLS(y, X).fit()\n",
    "    \n",
    "#     st, reg_data, ss2 = summary_table(res, alpha=0.05)\n",
    "#     fittedvalues = reg_data[:, 2]\n",
    "#     predict_mean_se  = reg_data[:, 3]\n",
    "#     predict_mean_ci_low, predict_mean_ci_upp = reg_data[:, 4:6].T\n",
    "#     predict_ci_low, predict_ci_upp = reg_data[:, 6:8].T\n",
    "        \n",
    "#     X = X[:,1]\n",
    "#     reg = hv.Curve(list(zip(X, fittedvalues)), label='Linear Fit').opts(tools=['hover'], color=color[-1], fontscale=fontscale, line_width=line_width, alpha=0.8)\n",
    "#     hv_predict_ci_low = hv.Curve(list(zip(X, predict_ci_low)), label='95% Confidence Band').opts(color='blue', line_dash='dashed')\n",
    "#     hv_predict_ci_upp = hv.Curve(list(zip(X, predict_ci_upp)), label='95% Confidence Band').opts(color='blue', line_dash='dashed')\n",
    "#     hv_predict_mean_ci_low = hv.Curve(list(zip(X, predict_mean_ci_low)), label='predict_mean_ci_low').opts(color='green', line_dash='dashed')\n",
    "#     hv_predict_mean_ci_upp = hv.Curve(list(zip(X, predict_mean_ci_upp)), label='predict_mean_ci_upp').opts(color='green', line_dash='dashed')\n",
    "#     predict_ci = hv_predict_ci_low * hv_predict_ci_upp * hv_predict_mean_ci_low * hv_predict_mean_ci_upp\n",
    "    \n",
    "#     predict_ci = hv.Area((X, predict_ci_low, predict_ci_upp), vdims=['y', 'y2'], label='95% Confidence Band').opts(alpha=0.2, color=color[-1])\n",
    "#     predict_mean_ci = hv.Area((X, predict_mean_ci_low, predict_mean_ci_upp), vdims=['y', 'y2'], label='95% Prediction Band').opts(alpha=0.4, color=color[-1])\n",
    "    reg, predict_ci, predict_mean_ci = get_linear_fit(counts, data, color=color[-1], fontscale=1.5, line_width=5)\n",
    "\n",
    "    corr = (sc1*reg * predict_ci * predict_mean_ci).opts(xlabel=counts[0] , ylabel=counts[1],\n",
    "                                            title=f'{title_pre} Correlation', xlim=(0, max_val), ylim=(0, max_val), tools=['hover'], width=650, height=500, legend_position='right')\n",
    "\n",
    "    cls_plot = hv.Layout(corr).cols(3)\n",
    "\n",
    "    return cls_plot\n",
    "\n",
    "cls = 'Prorocentrum micans'\n",
    "x_data = data[data['class'] == cls].reset_index(drop=True)\n",
    "plot_class_summary_2method([raw_counts[0], raw_counts[1]], x_data, relative=False, color=['blue', 'orange', 'black'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "\n",
    "x = x_data[raw_counts[0]].values\n",
    "y = x_data[raw_counts[1]].values\n",
    "X = sm.add_constant(x)\n",
    "res = sm.OLS(y, X).fit()\n",
    "print(res.summary())\n",
    "\n",
    "st, reg_data, ss2 = summary_table(res, alpha=0.05)\n",
    "fittedvalues = reg_data[:, 2]\n",
    "predict_mean_se  = reg_data[:, 3]\n",
    "predict_mean_ci_low, predict_mean_ci_upp = reg_data[:, 4:6].T\n",
    "predict_ci_low, predict_ci_upp = reg_data[:, 6:8].T\n",
    "\n",
    "X = X[:,1]\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(x, y, 'o', label=\"Raw Data\")\n",
    "ax.plot(X, fittedvalues, 'r-', label='Linear Fit')\n",
    "ax.plot(X, predict_ci_low, 'b--')\n",
    "ax.plot(X, predict_ci_upp, 'b--', label='95% Confidence Band')\n",
    "ax.plot(X, predict_mean_ci_low, 'g--')\n",
    "ax.plot(X, predict_mean_ci_upp, 'g--', label='95% Prediction Band')\n",
    "# ax.fill_between(X, predict_mean_ci_low, predict_mean_ci_upp, color='red', alpha='0.2')\n",
    "# ax.fill_between(X, predict_ci_low, predict_ci_upp, color='blue', alpha='0.2')\n",
    "ax.legend(loc='best');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, predict_ci_upp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Lingulodinium polyedra'\n",
    "x_data = data[data['class'] == cls].reset_index(drop=True)\n",
    "ci = 95\n",
    "sns.lmplot(x=raw_counts[0], y=raw_counts[1], data=x_data, ci=ci, fit_reg=True, n_boot=10000)\n",
    "sns.lmplot(x=raw_counts[0], y=raw_counts[2], data=x_data, ci=ci, fit_reg=True, n_boot=10000)\n",
    "sns.lmplot(x=raw_counts[1], y=raw_counts[2], data=x_data, ci=ci, fit_reg=True, n_boot=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Akashiwo'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Ceratium falcatiforme or fusus'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Ceratium furca'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Chattonella'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Cochlodinium'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Gyrodinium'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Lingulodinium polyedra'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%opts Scatter [tools=['hover'], width=600, height=600, legend_position='right', logx=True, logy=True, xlim=(-1, None), ylim=(-1, None)]\n",
    "# %%opts Slope [logx=True, logy=True, xlim=(-1, None), ylim=(-1, None)]\n",
    "\n",
    "cls = 'Prorocentrum micans'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Pseudo-nitzschia chain'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Akashiwo'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Ceratium falcatiforme or fusus'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Ceratium furca'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Cochlodinium'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Gyrodinium'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Lingulodinium polyedra'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Prorocentrum micans'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Pseudo-nitzschia chain'\n",
    "_plot_class_summary(cls, DATASET, DATASET, x_relative=False, y_relative=True, classifier=CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hab_rnd",
   "language": "python",
   "name": "hab_rnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
