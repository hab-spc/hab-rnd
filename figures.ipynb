{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as plt_colors\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')\n",
    "import scipy.stats as st\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "from holoviews import dim\n",
    "from IPython.display import Markdown, display\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rc('xtick', labelsize=14)     \n",
    "matplotlib.rc('ytick', labelsize=14)\n",
    "matplotlib.rc('axes', labelsize=14, titlesize=14)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from counts_analysis.c_utils import COUNTS_CSV, CLASSES, set_settings, set_counts\n",
    "\n",
    "#== Load Datasets ==#\n",
    "df = pd.read_csv(COUNTS_CSV['counts'])\n",
    "pred_df = pd.read_csv(COUNTS_CSV['counts-v10'])\n",
    "# Dataset without problematic classes (Gyrodinium, Pseudo-nitzchia chain)\n",
    "df_ = df[df['class'].isin(CLASSES)].reset_index(drop=True)\n",
    "data = df.copy()\n",
    "pred_data = pred_df.copy()\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "#=== Set count forms & settings ===#\n",
    "# COUNT\n",
    "# SETTING\n",
    "# Original raw counts\n",
    "rc_counts = set_counts('gtruth', 'raw count', micro_default=True)            \n",
    "rc_settings = set_settings(rc_counts)\n",
    "print('Example of setting\\n{}'.format(rc_settings))\n",
    "# Predicted raw counts\n",
    "rc_counts_pred = set_counts('predicted', 'raw count', micro_default=True)            \n",
    "rc_settings_pred = set_settings(rc_counts_pred)\n",
    "# Relative abundance\n",
    "rel_counts = set_counts('gtruth', 'relative abundance', micro_default=False)\n",
    "rel_counts = ['micro cells/mL relative abundance'] + list(rel_counts[1:])\n",
    "# Predicted Relative Abundance\n",
    "rel_counts_pred = set_counts('predicted', 'relative abundance', micro_default=False)\n",
    "rel_counts_pred = ['micro cells/mL relative abundance'] + list(rel_counts_pred[1:])\n",
    "\n",
    "#=== Set classifier gtruth vs predictions\n",
    "lab_gtruth_pred = ['lab {} raw count'.format(lbl) for lbl in ['gtruth', 'predicted']]\n",
    "pier_gtruth_pred = ['pier {} raw count'.format(lbl) for lbl in ['gtruth', 'predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = pd.read_csv('/data6/phytoplankton-db/counts/master_counts_v11-high.csv')\n",
    "low = pd.read_csv('/data6/phytoplankton-db/counts/master_counts_v11-low.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Experimenting different relative abundance combinations\n",
    "\n",
    "\"Other\" distribution computed to understand how HAB species would fare\n",
    "- 6/11/2020 3:03 PM microscopy \"other\" distribution MUCH lower than this. Seems that \"other\" dominates much of the camera samples\n",
    "\n",
    "\"\"\"\n",
    "dataset = pd.read_csv(COUNTS_CSV['counts-v10'])\n",
    "dataset = dataset[dataset['class'] == 'Other']\n",
    "print(dataset['lab gtruth relative abundance'].describe())\n",
    "dataset[['class', 'datetime', 'lab gtruth relative abundance', 'pier gtruth relative abundance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.copy()\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=18)     \n",
    "matplotlib.rc('ytick', labelsize=18)\n",
    "matplotlib.rc('axes', labelsize=18)\n",
    "\n",
    "printmd(\"# Total Counts Distribution\")\n",
    "current_palette_7 = sns.color_palette(\"muted\", 9)\n",
    "sns.set_palette(current_palette_7)\n",
    "\n",
    "# Time Series\n",
    "dataset.groupby('datetime')[rc_counts].sum().plot(kind='line', figsize=(18,5))\n",
    "plt.xlabel('Date Sampled')\n",
    "plt.ylabel('Total Counts')\n",
    "plt.legend(labels=['micro cells/mL', 'lab cells/1000s', 'pier cells/2000s'], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "# Distribution\n",
    "dataset.groupby('datetime')[rc_counts].sum().plot(kind='hist', figsize=(8,5), alpha=0.4)\n",
    "plt.xlabel('Total Counts')\n",
    "plt.legend(labels=['micro cells/mL', 'lab cells/1000s', 'pier cells/2000s'], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "# Box & Whiskers plot\n",
    "dataset.groupby('datetime')[rc_counts].sum().plot(kind='box', figsize=(8,5))\n",
    "plt.xlabel('Sampling Techniques')\n",
    "plt.ylabel('Total Counts')\n",
    "\n",
    "# Box & Whiskers plot (logged)\n",
    "dataset.groupby('datetime')[rc_counts].sum().plot(kind='box', figsize=(7,8), logy=True)\n",
    "plt.xlabel('Sampling Techniques')\n",
    "plt.ylabel('Total Counts (logged)')\n",
    "\n",
    "total_counts = df.groupby('datetime')[rc_counts].sum()\n",
    "print(total_counts.sum())\n",
    "total_counts.describe()\n",
    "\n",
    "def plot_correlation(counts, data,  ax_idx):\n",
    "    from validate_exp.v_utils import best_fit\n",
    "\n",
    "    sns.scatterplot(x=data[counts[0]], y=data[counts[1]], ax=ax_idx,\n",
    "                    label='lab (Y) - micro (X)')\n",
    "    sns.scatterplot(x=data[counts[0]], y=data[counts[2]], ax=ax_idx,\n",
    "                    label='pier (Y) - micro (X)')\n",
    "    sns.scatterplot(x=data[counts[1]], y=data[counts[2]], ax=ax_idx,\n",
    "                    label='pier (Y) - lab (X)')\n",
    "    Xfit, Yfit = best_fit(data[counts[0]], data[counts[1]], False, verbose=False)\n",
    "    ax_idx.plot(Xfit, Yfit)\n",
    "\n",
    "    Xfit, Yfit = best_fit(data[counts[0]], data[counts[2]], False, verbose=False)\n",
    "    ax_idx.plot(Xfit, Yfit)\n",
    "\n",
    "    Xfit, Yfit = best_fit(data[counts[1]], data[counts[2]], False, verbose=False)\n",
    "    ax_idx.plot(Xfit, Yfit)\n",
    "\n",
    "    ax_idx.set_xlabel('Count (X)')\n",
    "    ax_idx.set_ylabel('Count (Y)')\n",
    "\n",
    "    ymin, ymax = ax_idx.get_ylim()\n",
    "    xmin, xmax = ax_idx.get_xlim()\n",
    "\n",
    "    max_val = xmax if xmax >= ymax else ymax\n",
    "    ax_idx.set_ylim(0, max_val)\n",
    "    ax_idx.set_xlim(0, max_val)\n",
    "\n",
    "def plot_class_summary(counts, data):\n",
    "    matplotlib.rc('xtick', labelsize=18)     \n",
    "    matplotlib.rc('ytick', labelsize=18)\n",
    "    matplotlib.rc('axes', labelsize=18)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, figsize=(30,8))\n",
    "    \n",
    "    \n",
    "    #=== plot box whiskers plot ===#\n",
    "    dataset.groupby('datetime')[rc_counts].sum().plot(kind='box', ax=ax[0])\n",
    "    ax[0].set_xlabel('Sampling Techniques')\n",
    "    ax[0].set_ylabel('Total Counts')\n",
    "    \n",
    "    #=== plot time series ===#\n",
    "    dataset.groupby('datetime')[rc_counts].sum().plot(kind='line', ax=ax[1])\n",
    "    ax[1].set_xlabel('Date Sampled')\n",
    "    ax[1].set_ylabel('Total Counts')\n",
    "    \n",
    "    #=== plot corrrelationn plot ===#\n",
    "    plot_correlation(counts, data, ax_idx=ax[2])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('xtick', labelsize=18)     \n",
    "matplotlib.rc('ytick', labelsize=18)\n",
    "matplotlib.rc('axes', labelsize=18)\n",
    "matplotlib.rc('font', serif='Calibri') \n",
    "matplotlib.rc('font', family='sans-serif') \n",
    "\n",
    "printmd(\"# Total Counts Distribution\")\n",
    "current_palette_7 = sns.color_palette(\"muted\", 9)\n",
    "sns.set_palette(current_palette_7)\n",
    "\n",
    "def plot_class_distribution(dataset, counts, logged=False, relative=False):\n",
    "    #=== Box&Whisker ===#\n",
    "    sm = dataset[['class', 'datetime'] + list(counts)]\n",
    "    sm = sm.melt(id_vars=['class', 'datetime'], var_name=['setting'], value_name='count')\n",
    "    sm = sm.sort_values('class')\n",
    "#     sm['setting'] = sm['setting'].map({'micro cells/mL': 'micro', 'lab gtruth raw count': 'lab', 'pier gtruth raw count':'pier'})\n",
    "    plt.figure(figsize=(30, 7))\n",
    "    sns.boxplot(x='class', y='count', hue='setting', data=sm)\n",
    "    sns.stripplot(x='class', y='count', hue='setting', data=sm, color=\".25\", dodge=True)\n",
    "    \n",
    "    ylabel = 'Total Counts' if not relative else 'Relative Abundance'\n",
    "    if logged:\n",
    "        ylabel += ' (logged)'\n",
    "        plt.yscale('symlog')\n",
    "        plt.ylim(0)\n",
    "\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('Classes')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "    #=== Histogram ===#\n",
    "    num_cols = 5\n",
    "    fig, ax = plt.subplots(2, num_cols, figsize=(20,9))\n",
    "    for idx,cls in enumerate(sorted(sm['class'].unique())):\n",
    "        ak_sm = sm[sm['class'] == cls]\n",
    "        ak_sm_gp = ak_sm.groupby('setting')\n",
    "        sns.kdeplot(ak_sm_gp.get_group(counts[0])['count'], bw=1, ax=ax[idx//num_cols, idx%num_cols], label='micro')\n",
    "        sns.kdeplot(ak_sm_gp.get_group(counts[1])['count'], bw=1, ax=ax[idx//num_cols, idx%num_cols], label='lab')\n",
    "        sns.kdeplot(ak_sm_gp.get_group(counts[2])['count'], bw=1, ax=ax[idx//num_cols, idx%num_cols], label='pier')\n",
    "\n",
    "        ax[idx//num_cols, idx%num_cols].set_title(cls + \"\\nDistribution\")\n",
    "        ax[idx//num_cols, idx%num_cols].set_xlabel(ylabel)\n",
    "        ax[idx//num_cols, idx%num_cols].set_ylabel('Frequency')\n",
    "        \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "classes = ['Lingulodinium polyedra', 'Prorocentrum micans', 'Pseudo-nitzschia chain']\n",
    "def filter_classes(df, classes, high=True): return df[df['class'].isin(classes)].reset_index(drop=True) if high else df[~df['class'].isin(classes)].reset_index(drop=True)\n",
    "\n",
    "\"\"\"Overall\"\"\"\n",
    "plot_class_distribution(df, rc_counts, False)\n",
    "plot_class_distribution(df, rel_counts, False, relative=True)\n",
    "\n",
    "\n",
    "\"\"\"High & Low\"\"\"\n",
    "# plot_class_distribution(high, rel_counts, False)\n",
    "# plot_class_distribution(low, rel_counts, False)\n",
    "\n",
    "\"\"\"\n",
    "High & Low | Rare & Dominant\n",
    "\"\"\"\n",
    "# plot_class_distribution(df, rc_counts, False)\n",
    "# high_cls = filter_classes(high, classes)\n",
    "# plot_class_distribution(high_cls, rc_counts, False)\n",
    "# lowhigh_cls = filter_classes(high, classes, False)\n",
    "# plot_class_distribution(lowhigh_cls, rc_counts, False)\n",
    "\n",
    "# low_cls = filter_classes(low, classes)\n",
    "# plot_class_distribution(low_cls, rc_counts, False)\n",
    "# highlow_cls = filter_classes(low, classes, False)\n",
    "# plot_class_distribution(highlow_cls, rc_counts, False)\n",
    "\n",
    "\"\"\"Rare & Dominant\"\"\"\n",
    "# dominant = filter_classes(df, classes)\n",
    "# plot_class_distribution(dominant, rc_counts, True)\n",
    "# rare = filter_classes(df, classes, high=False)\n",
    "# plot_class_distribution(rare, rc_counts, True)\n",
    "\n",
    "\"\"\"Rare & Dominant | Relative Counts\"\"\"\n",
    "# dominant = filter_classes(df, classes)\n",
    "# plot_class_distribution(dominant, rel_counts, False, True)\n",
    "# rare = filter_classes(df, classes, high=False)\n",
    "# plot_class_distribution(rare, rel_counts, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute relative abundance of each date without certain classes\"\"\"\n",
    "def compute_relative_abundance(raw_count, data):\n",
    "    if 'micro' in raw_count:\n",
    "        relative_column = 'micro cells/mL relative abundance'\n",
    "    else:\n",
    "        relative_column = f'{raw_count.split()[0]} {raw_count.split()[1]} relative abundance'\n",
    "    data[relative_column] = data.groupby('datetime')[raw_count].apply(lambda x: x / x.sum() * 100.0 if sum(x) != 0 else x)\n",
    "    return data\n",
    "\n",
    "data = df[~df['class'].isin(['Gyrodinium', 'Pseudo-nitzschia chainn'])].reset_index(drop=True)\n",
    "# data = df[df['class'].isin(['Lingulodinium polyedra', 'Prorocentrum micans', 'Pseudo-nitzschia chain'])].reset_index(drop=True)\n",
    "\n",
    "for rc in rc_counts:\n",
    "    print(rc)\n",
    "    data = compute_relative_abundance(rc, data)\n",
    "filtered_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data[['class', 'datetime', 'lab gtruth relative abundance', 'micro cells/mL relative abundance', 'pier gtruth relative abundance']].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution(df, rel_counts, False, relative=True)\n",
    "display(df.groupby('class')[rel_counts].describe())\n",
    "plot_class_distribution(filtered_data, rel_counts, False, relative=True)\n",
    "display(filtered_data.groupby('class')[rel_counts].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 20\n",
    "matplotlib.rc('xtick', labelsize=fontsize)     \n",
    "matplotlib.rc('ytick', labelsize=fontsize)\n",
    "matplotlib.rc('axes', labelsize=fontsize, titlesize=fontsize)\n",
    "\n",
    "def plot_all_classes(dataset, counts, logged=False, relative=False):\n",
    "    sm = dataset[['class', 'datetime'] + list(counts)]\n",
    "    sm = sm.melt(id_vars=['class', 'datetime'], var_name=['setting'], value_name='count')\n",
    "    sm = sm.sort_values('class')\n",
    "#     sm['setting'] = sm['setting'].map({'micro cells/mL relative abundance': 'micro', 'lab gtruth relative abundance': 'lab', 'pier gtruth relative abundance':'pier'})\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='class', y='count', hue='setting', data=sm)\n",
    "#     sns.stripplot(x='class', y='count', hue='setting', data=sm, color=\".25\", dodge=True)\n",
    "\n",
    "    ylabel = 'Total Counts' if not relative else 'Relative Abundance'\n",
    "    if logged:\n",
    "        ylabel += ' (logged)'\n",
    "        plt.yscale('symlog')\n",
    "        plt.ylim(0)\n",
    "\n",
    "#     plt.ylim(0, 100)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('Classes')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.axes.xaxis.set_ticklabels([])\n",
    "#     ax.axes.yaxis.set_ticklabels([])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def compute_relative_abundance(raw_count, data):\n",
    "    if 'micro' in raw_count:\n",
    "        relative_column = 'micro cells/mL relative abundance'\n",
    "    else:\n",
    "        relative_column = f'{raw_count.split()[0]} {raw_count.split()[1]} relative abundance'\n",
    "    data[relative_column] = data.groupby('class')[raw_count].apply(lambda x: x / x.sum() * 100.0 if sum(x) != 0 else x)\n",
    "    return data\n",
    "\n",
    "# MODIFYING DATASET FOR ONLY SEASONAL DATES ONLY\n",
    "y = df.copy()\n",
    "def filter_classes(df, classes):\n",
    "    return df[~df['class'].isin(classes)].reset_index(drop=True)\n",
    "y = y[y['datetime'].isin(['2019-05-23', '2019-05-28', '2019-06-03'])]\n",
    "y = filter_classes(y, ['Gyrodinium', 'Chattonella', 'Pseudo-nitzschia chain'])\n",
    "y = y.sort_values('class')\n",
    "for rc in rc_counts:\n",
    "    print(rc)\n",
    "    y = compute_relative_abundance(rc, y)\n",
    "high = y.copy()\n",
    "\n",
    "y = df.copy()\n",
    "y = y[~y['datetime'].isin(['2019-05-23', '2019-05-28', '2019-06-03'])]\n",
    "y = filter_classes(y, ['Gyrodinium', 'Chattonella', 'Pseudo-nitzschia chain'])\n",
    "for rc in rc_counts:\n",
    "    print(rc)\n",
    "    y = compute_relative_abundance(rc, y)\n",
    "low = y.copy()\n",
    "\n",
    "# display(y[['class', 'datetime'] + list(rel_counts)])\n",
    "plot_all_classes(df, rc_counts, False, relative=False)\n",
    "# plot_all_classes(high, rel_counts, True, relative=True)\n",
    "# plot_all_classes(low, rel_counts, True, relative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%opts Scatter [tools=['hover'], width=600, height=600, legend_position='right', xlim=(-1, None), ylim=(-1, None), logx=True, logy=True]\n",
    "# %%opts Slope [xlim=(-1, None), ylim=(-1, None), logx=True, logy=True]\n",
    "\n",
    "def plot_correlation_hv(counts, data, cls, relative=False):\n",
    "    title_pre = '[Absolute Count]' if not relative else '[Relative Abundance]'\n",
    "    xy = 'Count' if not relative else 'Relative Abundance'\n",
    "    max_val = max(data[list(counts)].max()) + 10\n",
    "    \n",
    "    # correlation plot\n",
    "    dot_size, alpha = 12, 0.6\n",
    "    fs = 18\n",
    "\n",
    "    sc1 = hv.Scatter(data, counts[0], [counts[1], 'datetime', 'class'],\n",
    "                     label='lab - micro').opts(size=dot_size, alpha=alpha,\n",
    "                                               tools=['hover'])\n",
    "    reg = hv.Slope.from_scatter(sc1).opts(alpha=alpha, tools=['hover'], )\n",
    "\n",
    "    sc2 = hv.Scatter(data, counts[0], [counts[2], 'datetime', 'class'],\n",
    "                     label='pier - micro').opts(size=dot_size, alpha=alpha,\n",
    "                                                tools=['hover'], )\n",
    "    reg2 = hv.Slope.from_scatter(sc2).opts(alpha=alpha, tools=['hover'], )\n",
    "\n",
    "    sc3 = hv.Scatter(data, counts[1], [counts[2], 'datetime', 'class'],\n",
    "                     label='pier - lab').opts(size=dot_size, alpha=alpha,\n",
    "                                              tools=['hover'], )\n",
    "    reg3 = hv.Slope.from_scatter(sc3).opts(alpha=alpha, tools=['hover'], )\n",
    "    \n",
    "    corr = (sc1 * sc2 * sc3 * reg * reg2 * reg3).opts(xlabel=xy, ylabel=xy,\n",
    "                                                      title=f'{cls}',\n",
    "                                                      xlim=(0, max_val),\n",
    "                                                      ylim=(0, max_val), tools=['hover'],\n",
    "                                                      width=550, height=550,\n",
    "#                                                       legend_position='right',\n",
    "                                                      show_legend=False,\n",
    "                                                      fontsize={'title': fs, 'labels': fs, 'xticks': fs, 'yticks': fs}).redim.range(y=(0.01, 1))\n",
    "    return corr.redim.range(y=(0.01, None), x=(0.01, None))\n",
    "\n",
    "def compute_relative_abundance(raw_count, data):\n",
    "    if 'micro' in raw_count:\n",
    "        relative_column = 'micro cells/mL relative abundance'\n",
    "    else:\n",
    "        relative_column = f'{raw_count.split()[0]} {raw_count.split()[1]} relative abundance'\n",
    "    data[relative_column] = data.groupby('class')[raw_count].apply(lambda x: x / x.sum() * 100.0 if sum(x) != 0 else x)\n",
    "    return data\n",
    "\n",
    "y = df.copy()\n",
    "for rc in rc_counts:\n",
    "    print(rc)\n",
    "    y = compute_relative_abundance(rc, y)\n",
    "for rc in rc_counts_pred:\n",
    "    print(rc)\n",
    "    y = compute_relative_abundance(rc, y)\n",
    "y = y[~y['datetime'].isin(['2019-05-23', '2019-05-28', '2019-06-03'])].reset_index(drop=True)\n",
    "cls = 'Akashiwo'\n",
    "\n",
    "COUNT = rel_counts_pred\n",
    "def filter_classes(df, classes):\n",
    "    return df[df['class'].isin(classes)].reset_index(drop=True)\n",
    "cls_df = filter_classes(y, [cls])\n",
    "corr = plot_correlation_hv(COUNT, cls_df, cls, True)\n",
    "\n",
    "clsses = ['Ceratium falcatiforme or fusus', 'Ceratium furca', 'Cochlodinium', 'Lingulodinium polyedra', 'Prorocentrum micans']\n",
    "# clsses = ['Ceratium furca', 'Cochlodinium', 'Lingulodinium polyedra', 'Prorocentrum micans']\n",
    "for cls in clsses:\n",
    "    print(cls)\n",
    "    cls_df = filter_classes(y, [cls])\n",
    "    corr += plot_correlation_hv(COUNT, cls_df, cls, True)\n",
    "hv.Layout(corr.redim.range(y=(0.01, None), x=(0.01, None))).cols(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('xtick', labelsize=10)     \n",
    "matplotlib.rc('ytick', labelsize=10)\n",
    "matplotlib.rc('axes', labelsize=10)\n",
    "\n",
    "current_palette_7 = sns.color_palette(\"Set2\", 3)\n",
    "sns.set_palette(current_palette_7[::-1])\n",
    "\n",
    "def rsquared(x, y):\n",
    "    \"\"\" Return R^2 where x and y are array-like.\"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    X = np.hstack((np.array([1] * len(x)).reshape(-1, 1), np.array(x).reshape(-1, 1)))\n",
    "    mod = sm.OLS(np.array(y).reshape(-1, 1), X)\n",
    "    res = mod.fit()\n",
    "    return res\n",
    "\n",
    "def best_fit(X, Y, log_scale=False, verbose=False):\n",
    "    if log_scale:\n",
    "        # slope, intercept, \\\n",
    "        # r_value, p_value, std_err = linregress(np.log10(np.array(X) + 1), np.log10(np.array(Y)+1))\n",
    "        # Xfit = np.logspace(-1, 4, base=10)\n",
    "        # Yfit = Xfit * slope + intercept\n",
    "\n",
    "        x1 = [x for (x, y) in sorted(zip(X, Y))]\n",
    "        y1 = [y for (x, y) in sorted(zip(X, Y))]\n",
    "        x = np.array([np.log(x) if x>=1 else 1 for x in x1])\n",
    "        y = np.array([np.log(x) if x>=1 else 1 for x in y1])\n",
    "        k,m = np.polyfit(x, y, deg=1)\n",
    "        Xfit = x1\n",
    "        Yfit = np.exp(m) * x1**(k)\n",
    "#         Yfit = fit[0] * x + fit[1]\n",
    "\n",
    "\n",
    "    else:\n",
    "        xbar = sum(X) / len(X)\n",
    "        ybar = sum(Y) / len(Y)\n",
    "        n = len(X)  # or len(Y)\n",
    "\n",
    "        numer = sum([xi * yi for xi, yi in zip(X, Y)]) - n * xbar * ybar\n",
    "        denum = sum([xi ** 2 for xi in X]) - n * xbar ** 2\n",
    "\n",
    "        b = numer / denum if denum !=0 else 0\n",
    "        a = ybar - b * xbar\n",
    "\n",
    "        Yfit = [a + b * xi for xi in X]\n",
    "        Xfit = X\n",
    "\n",
    "    # Compute R2 value and other statistics from statsmodel\n",
    "    res = rsquared(X, Y)\n",
    "\n",
    "    if verbose:\n",
    "        print(res.summary())\n",
    "    return Xfit, Yfit\n",
    "\n",
    "def plot_correlation(data, counts, logged=False):\n",
    "    NUM_COLS=5\n",
    "    fig, ax = plt.subplots(2, NUM_COLS, figsize=(20, 8))\n",
    "    sns.scatterplot(x=data[counts[0]], y=data[counts[1]], ax=ax[0,0], label='lab (Y) - micro (X)')\n",
    "    sns.scatterplot(x=data[counts[0]], y=data[counts[2]], ax=ax[0,0], label='pier (Y) - micro (X)')\n",
    "    sns.scatterplot(x=data[counts[1]], y=data[counts[2]], ax=ax[0,0], label='pier (Y) - lab (X)')\n",
    "\n",
    "    ax[0,0].set_xlabel('Count (X)')\n",
    "    ax[0,0].set_ylabel('Count (Y)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    classes = sorted(data['class'].unique())\n",
    "    for i_ax,cls in enumerate(classes):\n",
    "        cls_df = data[data['class']==cls]\n",
    "        ax_idx = ax[int((i_ax+1) / NUM_COLS), (i_ax+1) % NUM_COLS]\n",
    "        sns.scatterplot(x=cls_df[counts[0]], y=cls_df[counts[1]], ax=ax_idx, label='lab (Y) - micro (X)')\n",
    "        sns.scatterplot(x=cls_df[counts[0]], y=cls_df[counts[2]], ax=ax_idx, label='pier (Y) - micro (X)')\n",
    "        sns.scatterplot(x=cls_df[counts[1]], y=cls_df[counts[2]], ax=ax_idx, label='pier (Y) - lab (X)')\n",
    "        Xfit, Yfit = best_fit(cls_df[counts[0]], cls_df[counts[1]], logged, verbose=False)\n",
    "        ax_idx.plot(Xfit, Yfit)\n",
    "\n",
    "        Xfit, Yfit = best_fit(cls_df[counts[0]], cls_df[counts[2]], logged, verbose=False)\n",
    "        ax_idx.plot(Xfit, Yfit)\n",
    "\n",
    "        Xfit, Yfit = best_fit(cls_df[counts[1]], cls_df[counts[2]], logged, verbose=False)\n",
    "        ax_idx.plot(Xfit, Yfit)\n",
    "\n",
    "        ax_idx.set_xlabel('Count (X)')\n",
    "        ax_idx.set_ylabel('Count (Y)')\n",
    "        \n",
    "        ymin, ymax = ax_idx.get_ylim()\n",
    "        xmin, xmax = ax_idx.get_xlim()\n",
    "        \n",
    "        max_val = xmax if xmax >= ymax else ymax\n",
    "        ax_idx.set_ylim(0, max_val)\n",
    "        ax_idx.set_xlim(0, max_val)\n",
    "        ax_idx.set_yscale('symlog')\n",
    "        ax_idx.set_xscale('symlog')\n",
    "\n",
    "        ax_idx.set_title(cls)\n",
    "#         set_plotting_opts(ax_idx, logged=LOGGED)\n",
    "        plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSL_COUNTS = True\n",
    "PREDICTED_COUNTS = False\n",
    "RELATIVE_COUNTS = False\n",
    "HIGH_AND_LOW = False\n",
    "\n",
    "printmd('# Overall Abundance Days')\n",
    "data = filtered_data.copy()\n",
    "if ABSL_COUNTS:\n",
    "    printmd('### Absolute Counts')\n",
    "    plot_correlation(data, rc_counts, logged=True)\n",
    "\n",
    "if PREDICTED_COUNTS:\n",
    "    printmd('### Predicted Absolute Counts')\n",
    "    pred_data = pred_df.copy()\n",
    "    pred_data = pred_data[pred_data['class'] != \"Other\"].reset_index(drop=True)\n",
    "    plot_correlation(pred_data, rc_counts_pred)\n",
    "\n",
    "if RELATIVE_COUNTS:\n",
    "    printmd('### Relative Counts')\n",
    "    plot_correlation(data, rel_counts)\n",
    "\n",
    "if HIGH_AND_LOW:\n",
    "    printmd('# Low Abundance Days')\n",
    "    data = low.copy()\n",
    "    if ABSL_COUNTS:\n",
    "        printmd('### Absolute Counts')\n",
    "        plot_correlation(data, rc_counts)\n",
    "\n",
    "    if PREDICTED_COUNTS:\n",
    "        printmd('### Predicted Absolute Counts')\n",
    "        pred_data = pred_df.copy()\n",
    "        pred_data = pred_data[pred_data['class'] != \"Other\"].reset_index(drop=True)\n",
    "        plot_correlation(pred_data, rc_counts_pred)\n",
    "\n",
    "    if RELATIVE_COUNTS:\n",
    "        printmd('### Relative Counts')\n",
    "        plot_correlation(data, rel_counts)\n",
    "\n",
    "    printmd('# High Abundance Days')\n",
    "    data = high.copy()\n",
    "    if ABSL_COUNTS:\n",
    "        printmd('### Absolute Counts')\n",
    "        plot_correlation(data, rc_counts)\n",
    "\n",
    "    if PREDICTED_COUNTS:\n",
    "        printmd('### Predicted Absolute Counts')\n",
    "        pred_data = pred_df.copy()\n",
    "        pred_data = pred_data[pred_data['class'] != \"Other\"].reset_index(drop=True)\n",
    "        plot_correlation(pred_data, rc_counts_pred)\n",
    "\n",
    "    if RELATIVE_COUNTS:\n",
    "        printmd('### Relative Counts')\n",
    "        plot_correlation(data, rel_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Abhishek Bhatia's data & scatter plot.\n",
    "x = np.array([  29.,   36.,    8.,   32.,   11.,   60.,   16.,  242.,   36.,\n",
    "               115.,    5.,  102.,    3.,   16.,   71.,    0.,    0.,   21.,\n",
    "               347.,   19.,   12.,  162.,   11.,  224.,   20.,    1.,   14.,\n",
    "                 6.,    3.,  346.,   73.,   51.,   42.,   37.,  251.,   21.,\n",
    "               100.,   11.,   53.,  118.,   82.,  113.,   21.,    0.,   42.,\n",
    "                42.,  105.,    9.,   96.,   93.,   39.,   66.,   66.,   33.,\n",
    "               354.,   16.,  602.])\n",
    "y = np.array([ 30,  47, 115,  50,  40, 200, 120, 168,  39, 100,   2, 100,  14,\n",
    "               50, 200,  63,  15, 510, 755, 135,  13,  47,  36, 425,  50,   4,\n",
    "               41,  34,  30, 289, 392, 200,  37,  15, 200,  50, 200, 247, 150,\n",
    "              180, 147, 500,  48,  73,  50,  55, 108,  28,  55, 100, 500,  61,\n",
    "              145, 400, 500,  40, 250])\n",
    "fig = plt.figure()\n",
    "ax=plt.gca() \n",
    "ax.scatter(x,y,c=\"blue\",alpha=0.95,edgecolors='none', label='data')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "\n",
    "newX = np.logspace(0, 3, base=10)  # Makes a nice domain for the fitted curves.\n",
    "                                   # Goes from 10^0 to 10^3\n",
    "                                   # This avoids the sorting and the swarm of lines.\n",
    "\n",
    "# Let's fit an exponential function.  \n",
    "# This looks like a line on a lof-log plot.\n",
    "def myExpFunc(x, a, b):\n",
    "    return a * np.power(x, b)\n",
    "popt, pcov = curve_fit(myExpFunc, x, y)\n",
    "plt.plot(newX, myExpFunc(newX, *popt), 'r-', \n",
    "         label=\"({0:.3f}*x**{1:.3f})\".format(*popt))\n",
    "print(\"Exponential Fit: y = (a*(x**b))\")\n",
    "print(\"\\ta = popt[0] = {0}\\n\\tb = popt[1] = {1}\".format(*popt))\n",
    "\n",
    "# Let's fit a more complicated function.\n",
    "# This won't look like a line.\n",
    "def myComplexFunc(x, a, b, c):\n",
    "    return a * np.power(x, b) + c\n",
    "popt, pcov = curve_fit(myComplexFunc, x, y)\n",
    "plt.plot(newX, myComplexFunc(newX, *popt), 'g-', \n",
    "         label=\"({0:.3f}*x**{1:.3f}) + {2:.3f}\".format(*popt))\n",
    "print(\"Modified Exponential Fit: y = (a*(x**b)) + c\")\n",
    "print(\"\\ta = popt[0] = {0}\\n\\tb = popt[1] = {1}\\n\\tc = popt[2] = {2}\".format(*popt))\n",
    "\n",
    "ax.grid(b='on')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('xtick', labelsize=10)     \n",
    "matplotlib.rc('ytick', labelsize=10)\n",
    "matplotlib.rc('axes', labelsize=10)\n",
    "\n",
    "\n",
    "def plot_predicted_correlation(data, lab, pier):\n",
    "    from validate_exp.v_utils import best_fit\n",
    "    from validate_exp.stat_fns import mase\n",
    "\n",
    "    NUM_COLS=5\n",
    "    fig, ax = plt.subplots(2, NUM_COLS, figsize=(20, 8))\n",
    "    sns.scatterplot(x=data[lab[0]], y=data[lab[1]], ax=ax[0, 0], label='lab')\n",
    "    sns.scatterplot(x=data[pier[0]], y=data[pier[1]], ax=ax[0, 0], label='pier')\n",
    "\n",
    "    ax[0,0].set_xlabel('Gtruth Count')\n",
    "    ax[0,0].set_ylabel('Predicted Count')\n",
    "\n",
    "    scores_df = pd.DataFrame(columns=['class', 'camera', 'mase'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    classes = sorted(data['class'].unique())\n",
    "    for i_ax,cls in enumerate(classes):\n",
    "        cls_df = data[data['class']==cls]\n",
    "        ax_idx = ax[int((i_ax+1) / NUM_COLS), (i_ax+1) % NUM_COLS]\n",
    "        sns.scatterplot(x=cls_df[lab[0]], y=cls_df[lab[1]], ax=ax_idx, label='lab')\n",
    "        sns.scatterplot(x=cls_df[pier[0]], y=cls_df[pier[1]], ax=ax_idx, label='pier')\n",
    "        \n",
    "        print(cls)\n",
    "        lm = mase(cls_df[lab[0]], cls_df[lab[1]])\n",
    "        pm = mase(cls_df[pier[0]], cls_df[pier[1]])\n",
    "        print('MASE (Lab): {}'.format(lm))\n",
    "        print('MASE (Pier): {}\\n\\n'.format(pm))\n",
    "        scores_df = scores_df.append({'class':cls, 'camera': 'lab', 'mase': lm}, ignore_index=True)\n",
    "        scores_df = scores_df.append({'class':cls, 'camera': 'pier', 'mase': pm}, ignore_index=True)\n",
    "        \n",
    "        Xfit, Yfit = best_fit(cls_df[lab[0]], cls_df[lab[1]], False, verbose=False)\n",
    "        ax_idx.plot(Xfit, Yfit, color='blue', marker='_')\n",
    "\n",
    "        Xfit, Yfit = best_fit(cls_df[pier[0]], cls_df[pier[1]], False, verbose=False)\n",
    "        ax_idx.plot(Xfit, Yfit, color='orange', marker='_')\n",
    "\n",
    "        ax_idx.set_xlabel('Gtruth Count')\n",
    "        ax_idx.set_ylabel('Predicted Count')  \n",
    "\n",
    "        ax_idx.set_title(cls)\n",
    "    #     set_plotting_opts(ax_idx, logged=LOGGED)\n",
    "        plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    sns.barplot(x='class', y='mase', hue='camera', data=scores_df)\n",
    "    plt.show()\n",
    "    return scores_df\n",
    "\n",
    "pred_data = pred_df.copy()\n",
    "pred_data = pred_data[pred_data['class'] != \"Other\"].reset_index(drop=True)\n",
    "scores_df = plot_predicted_correlation(pred_data, lab_gtruth_pred, pier_gtruth_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df1 = scores_df.copy()\n",
    "scores_df1 = scores_df1[scores_df1['camera'] == 'pier']\n",
    "display(scores_df1['mase'].describe())\n",
    "\n",
    "scores_df1 = scores_df.copy()\n",
    "scores_df1 = scores_df1[scores_df1['camera'] == 'lab']\n",
    "display(scores_df1['mase'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SCALED WORK\n",
    "\"\"\"\n",
    "t = data.groupby('class').get_group('Prorocentrum micans')\n",
    "t.loc[:, rel_counts[1]] /= 100.\n",
    "t.loc[:, rel_counts[2]] /= 100.\n",
    "\n",
    "def plot_scatter(df, counts, logged=False):\n",
    "    from validate_exp.v_utils import best_fit\n",
    "\n",
    "    sns.scatterplot(x=df[counts[0]], y=df[counts[1]], label='lab (Y) - micro (X)')\n",
    "    Xfit, Yfit = best_fit(df[counts[0]], df[counts[1]], logged, verbose=False)\n",
    "    plt.plot(Xfit, Yfit, color='blue')\n",
    "\n",
    "    sns.scatterplot(x=df[counts[0]], y=df[counts[2]], label='pier (Y) - micro (X)')\n",
    "    Xfit, Yfit = best_fit(df[counts[0]], df[counts[2]], logged, verbose=False)\n",
    "    plt.plot(Xfit, Yfit, color='orange')\n",
    "\n",
    "    sns.scatterplot(x=df[counts[1]], y=df[counts[2]], label='pier (Y) - lab (X)')\n",
    "    Xfit, Yfit = best_fit(df[counts[1]], df[counts[2]], logged, verbose=False)\n",
    "    plt.plot(Xfit, Yfit, color='green')\n",
    "    \n",
    "    if logged:\n",
    "        plt.xscale('symlog')\n",
    "        plt.yscale('symlog')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "t['scaling1'] = t['micro cells/mL'] / t[rel_counts[1]]\n",
    "t['test1'] = t[rel_counts[1]] * t['scaling1']\n",
    "t['test1'] = t['test1'].fillna(0)\n",
    "\n",
    "t['scaling2'] = t['micro cells/mL'] / t[rel_counts[2]]\n",
    "t['test2'] = t[rel_counts[2]] * t['scaling2']\n",
    "\n",
    "print(t[['micro cells/mL', rel_counts[1], 'lab gtruth total abundance', 'scaling1', 'test1', rel_counts[2], 'test2']])\n",
    "plot_scatter(t, ['micro cells/mL', 'test1', 'test2'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "\n",
    "data[rel_counts[1]] /= 100.\n",
    "data[rel_counts[2]] /= 100.\n",
    "\n",
    "lab = []\n",
    "for i in lab_scale:\n",
    "    lab.extend([i]*9)\n",
    "pier = []\n",
    "for i in pier_scale:\n",
    "    pier.extend([i]*9)\n",
    "data['lab_scale'] = lab\n",
    "data['pier_scale'] = pier\n",
    "\n",
    "data['test1'] = data['lab_scale'] * data[rel_counts[1]]\n",
    "data['test2'] = data['pier_scale'] * data[rel_counts[1]]\n",
    "plot_correlation(data, ['micro cells/mL', 'test1', 'test2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = t['datetime'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_scale = [209.56185858585857,\n",
    " 67.63110000000002,\n",
    " 430.7411294498382,\n",
    " 111.36646808510639,\n",
    " 120.40339999999998,\n",
    " 84.57114285714286,\n",
    " 27.5385,\n",
    " 17.528000000000002,\n",
    " 8,\n",
    " 9.436,\n",
    " 4.078,\n",
    " 40.78158333333332,\n",
    " 126.14485714285715,\n",
    " 54.91462500000001,\n",
    " 6.0064,\n",
    " 34.4175,\n",
    " 1351.8,\n",
    " 3,\n",
    " 115.64233333333333,\n",
    " 19,\n",
    " 16,\n",
    " 10,\n",
    " 41.6185,\n",
    " 10,\n",
    " 12,\n",
    " 13]\n",
    "pier_scale = [226.0693222060958,\n",
    " 76.54969971671387,\n",
    " 609.2260073529412,\n",
    " 116.65848275862069,\n",
    " 125.30670588235294,\n",
    " 106.41286363636362,\n",
    " 33.38,\n",
    " 11.0176,\n",
    " 13,\n",
    " 25.948999999999998,\n",
    " 3.398333333333334,\n",
    " 54.187294117647056,\n",
    " 136.74526530612243,\n",
    " 61.46822222222221,\n",
    " 9.385,\n",
    " 37.859249999999996,\n",
    " 69,\n",
    " 115.144,\n",
    " 131.593,\n",
    " 9,\n",
    " 20.39,\n",
    " 1.252,\n",
    " 59.45499999999999,\n",
    " 26.701333333333334,\n",
    " 568.632,\n",
    " 10]\n",
    "\n",
    "lab_dt_scale = dict(zip(dates, lab_scale))\n",
    "pier_dt_scale = dict(zip(dates, pier_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hab_rnd",
   "language": "python",
   "name": "hab_rnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
